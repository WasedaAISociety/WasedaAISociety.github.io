<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Document</title>
</head>
<body>
  <div id="playground">
    <p>
A series of studies experimentally investigated whether Uncanny Valley effects exist for static images of robot faces. Mathur MB & Reichling DB[25] used two complementary sets of stimuli spanning the range from very mechanical to very human-like: first, a sample of 80 objectively chosen robot face images from Internet searches, and second, a morphometrically and graphically controlled 6-face series set of faces. They asked subjects to explicitly rate the likability of each face. To measure trust toward each face, subjects completed a one-shot investment game to indirectly measure how much money they were willing to "wager" on a robot's trustworthiness. Both stimulus sets showed a robust Uncanny Valley effect on explicitly-rated likability and a more context-dependent Uncanny Valley on implicitly-rated trust. Their exploratory analysis of one proposed mechanism for the Uncanny Valley, perceptual confusion at a category boundary, found that category confusion occurs in the Uncanny Valley but does not mediate the effect on social and emotional responses.
One study conducted in 2009 examined the evolutionary mechanism behind the aversion associated with the uncanny valley. A group of five monkeys were shown three images: two different 3D monkey faces (realistic, unrealistic), and a real photo of a monkey's face. The monkeys' eye-gaze was used as a proxy for preference or aversion. Since the realistic 3D monkey face was looked at less than either the real photo, or the unrealistic 3D monkey face, this was interpreted as an indication that the monkey participants found the realistic 3D face aversive, or otherwise preferred the other two images. As one would expect with the uncanny valley, more realism can lead to less positive reactions, and this study demonstrated that neither human-specific cognitive processes, nor human culture explain the uncanny valley. In other words, this aversive reaction to realism can be said to be evolutionary in origin.[32]
As of 2011, researchers at University of California, San Diego and California Institute for Telecommunications and Information Technology are measuring human brain activations related to the uncanny valley.[33][34] In one study using fMRI, a group of cognitive scientists and roboticists found the biggest differences in brain responses for uncanny robots in parietal cortex, on both sides of the brain, specifically in the areas that connect the part of the brain’s visual cortex that processes bodily movements with the section of the motor cortex thought to contain mirror neurons. The researchers say they saw, in essence, evidence of mismatch or perceptual conflict.[18] The brain "lit up" when the human-like appearance of the android and its robotic motion "didn’t compute". Ayşe Pınar Saygın, an assistant professor from UCSD, says "The brain doesn’t seem selectively tuned to either biological appearance or biological motion per se. What it seems to be doing is looking for its expectations to be met – for appearance and motion to be congruent."[35][36][37]
Viewer perception of facial expression and speech and the uncanny valley in realistic, human-like characters intended for video games and film is being investigated by Tinwell et al., 2011.[38] Consideration is also given by Tinwell et al. (2010) as to how the uncanny may be exaggerated for antipathetic characters in survival horror games.[39] Building on the body of work already undertaken in android science, this research intends to build a conceptual framework of the uncanny valley using 3D characters generated in a real-time gaming engine. The goal is to analyze how cross-modal factors of facial expression and speech can exaggerate the uncanny. Tinwell et al., 2011[40] have also introduced the notion of an unscalable uncanny wall that suggests that a viewer’s discernment for detecting imperfections in realism will keep pace with new technologies in simulating realism. A summary of Dr Angela Tinwell's research on the Uncanny Valley, psychological reasons behind the Uncanny Valley and how designers may overcome the uncanny in human-like virtual characters is provided in her book, The Uncanny Valley in Games and Animation by CRC Press.[41]
(Uncanny valley from Wikipedia)
    </p>
  </div>

  <script type="text/javascript">

    var myHilitor2;
    var wordList1 = ["the", "in", "have", "to", "would", "it", "apple"];
    var wordList2 = {"the": 0, "in": 1, "have": 2, "to": 0, "would": 1, "it": 2, "apple": 2};

    // Original JavaScript code by Chirp Internet: www.chirp.com.au
    // Please acknowledge use of this code by including this header.

    function Hilitor(id, tag)
    {

      var targetNode = document.getElementById(id) || document.body;
      var hiliteTag = tag || "EM";
      var skipTags = new RegExp("^(?:" + hiliteTag + "|SCRIPT|FORM|SPAN)$");
      var colors = ["#FF0000", "#FDFF00","#002BFF"];
      var wordColor = [];
      var matchRegex = "";
      var openLeft = false;
      var openRight = false;

      this.setMatchType = function(type)
      {
        this.openLeft = this.openRight = false;
      };

      this.setRegex = function(input)
      {
        input = input.replace(/^[^\w]+|[^\w]+$/g, "").replace(/[^\w'-]+/g, "|");
        var re = "(" + input + ")";
        re = "\\b" + re + "\\b";
        matchRegex = new RegExp(re, "i");
      };

      this.getRegex = function()
      {
        var retval = matchRegex.toString();
        retval = retval.replace(/(^\/(\\b)?|\(|\)|(\\b)?\/i$)/g, "");
        retval = retval.replace(/\|/g, " ");
        return retval;
      };

      // recursively apply word highlighting
      this.hiliteWords = function(node)
      {
        if(node === undefined || !node) return;
        if(!matchRegex) return;
        if(skipTags.test(node.nodeName)) return;

        if(node.hasChildNodes()) {
          for(var i=0; i < node.childNodes.length; i++)
            this.hiliteWords(node.childNodes[i]);
        }
        if(node.nodeType == 3) { // NODE_TEXT
          if((nv = node.nodeValue) && (regs = matchRegex.exec(nv))) {
            if(!wordColor[regs[0].toLowerCase()]) {
              wordColor[regs[0].toLowerCase()] = colors[wordList2[regs[0].toLowerCase()]];
            }

            var match = document.createElement(hiliteTag);
            match.appendChild(document.createTextNode(regs[0]));
            match.style.backgroundColor = wordColor[regs[0].toLowerCase()];
            match.style.fontStyle = "inherit";
            match.style.color = "#000";

            var after = node.splitText(regs.index);
            after.nodeValue = after.nodeValue.substring(regs[0].length);
            node.parentNode.insertBefore(match, after);
          }
        };
      };

      // remove highlighting
      this.remove = function()
      {
        var arr = document.getElementsByTagName(hiliteTag);
        while(arr.length && (el = arr[0])) {
          var parent = el.parentNode;
          parent.replaceChild(el.firstChild, el);
          parent.normalize();
        }
      };

      // start highlighting at target node
      this.apply = function(input)
      {
        if(input === undefined || !input) return;
        this.setRegex(input);
        this.hiliteWords(targetNode);
      };
    }

    document.addEventListener("DOMContentLoaded", function() {
      myHilitor2 = new Hilitor("playground");
      myHilitor2.setMatchType("null");
      for (var i = 0; i < wordList1.length; i++) {
        myHilitor2.apply(wordList1[i]);
      }
    }, false);

    var sWords = document.getElementById('playground').innerText.toLowerCase().trim().replace(/[,;.]/g,'').split(/[\s\/]+/g).sort();
    filteredsWords = sWords.filter(function (x, i, self) {return self.indexOf(x) === i;});
    console.log(filteredsWords);
  </script>
</body>
</html>
